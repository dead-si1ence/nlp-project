My name is Montaser

To train the model: Optimize value of parameters to minimize loss
31
To train a model, we gradually adjust parameters to minimize a loss
â€¢ Recall: ğœƒ represents all the
model parameters, in one
long vector
â€¢ In our case, with
d-dimensional vectors and
V-many words, we have â†’
â€¢ Remember: every word has
two vectors
â€¢ We optimize these parameters by walking down the gradient (see right figure)
â€¢ We compute all vector gradients!
if there are a 100 dimensional word representation, then they're sort of a 100 parameters of aardvark and context, etc
